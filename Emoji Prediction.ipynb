{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Including required python libraries used in this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, SimpleRNN,LSTM, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading train emoji and test emoji data which are attached in the repo\n",
    "train = pd.read_csv('train_emoji.csv',header=None)\n",
    "test = pd.read_csv('test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data by showing first 5 rows of the train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data by showing first 5 rows of the test data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary for some emoji's, consisting of key - number and value - emoji \n",
    "emoji_dict = { 0 : \":heart:\", 1 : \":baseball:\", 2 : \":smile:\", 3 : \":disappointed:\", 4 : \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§\n",
      "1 ‚öæ\n",
      "2 üòÑ\n",
      "3 üòû\n",
      "4 üç¥\n"
     ]
    }
   ],
   "source": [
    "# Printing each emoji icon by emojizing each emoji\n",
    "for ix in emoji_dict.keys():\n",
    "    print (ix,end=\" \")\n",
    "    print (emoji.emojize(emoji_dict[ix], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132,) (56,) (56,)\n",
      "-------------------------\n",
      "never talk to me again 3\n"
     ]
    }
   ],
   "source": [
    "# Creating training and testing data\n",
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "\n",
    "X_test = test[0]\n",
    "Y_test = test[1]\n",
    "\n",
    "print (X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "print (\"-------------------------\")\n",
    "print (X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ambika/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ambika/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Splitting the train data from sentences to words\n",
    "for ix in range(X_train.shape[0]):\n",
    "    X_train[ix] = X_train[ix].split()\n",
    "\n",
    "# Splitting the test data from sentences to words\n",
    "for ix in range(X_test.shape[0]):\n",
    "    X_test[ix] = X_test[ix].split()\n",
    "    \n",
    "# Converting labels into categorical form\n",
    "Y_train = np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] [0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Now checking the above conversion by printing train and test data at 0th index\n",
    "print (X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([ 4,  5, 26, 35, 20, 21, 11,  5,  1,  4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check maximum length of sentence in training data\n",
    "np.unique(np.array([len(ix) for ix in X_train]) , return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 4, 5, 6, 7, 8]), array([ 3, 12, 16, 17,  3,  4,  1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check maximum length of senetence in testing data\n",
    "np.unique(np.array([len(ix) for ix in X_test]) , return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  embeddings dictionary with key = word and value = list of words in glove vector\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking length of a particular word\n",
    "embeddings_index[\"i\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31093674898147583"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "# Checking cosine similarity of words happy and sad\n",
    "spatial.distance.cosine(embeddings_index[\"happy\"], embeddings_index[\"sad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18572336435317993"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking cosine similarity of words India and Delhi\n",
    "spatial.distance.cosine(embeddings_index[\"india\"], embeddings_index[\"delhi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19746702909469604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking cosine similarity of words france and paris\n",
    "spatial.distance.cosine(embeddings_index[\"france\"], embeddings_index[\"paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the embedding matrix\n",
    "embedding_matrix_train = np.zeros((X_train.shape[0], 10, 50))\n",
    "embedding_matrix_test = np.zeros((X_test.shape[0], 10, 50))\n",
    "\n",
    "for ix in range(X_train.shape[0]):\n",
    "    for ij in range(len(X_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(X_test.shape[0]):\n",
    "    for ij in range(len(X_test[ix])):\n",
    "        embedding_matrix_test[ix][ij] = embeddings_index[X_test[ix][ij].lower()]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print (embedding_matrix_train.shape, embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 15,941\n",
      "Trainable params: 15,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple RNN network to classify the emoji class from an input Sentence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Loss and Optimiser for the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 1.9733 - acc: 0.1818\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 368us/step - loss: 1.8078 - acc: 0.2273\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 389us/step - loss: 1.8040 - acc: 0.2348\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 416us/step - loss: 1.7699 - acc: 0.2652\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 413us/step - loss: 1.4999 - acc: 0.3485\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 336us/step - loss: 1.5025 - acc: 0.3939\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 340us/step - loss: 1.4341 - acc: 0.4015\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 369us/step - loss: 1.4411 - acc: 0.3485\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 308us/step - loss: 1.3512 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 402us/step - loss: 1.3387 - acc: 0.4621\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 473us/step - loss: 1.2666 - acc: 0.4848\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 490us/step - loss: 1.2184 - acc: 0.5379\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 323us/step - loss: 1.1922 - acc: 0.5076\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 422us/step - loss: 1.1656 - acc: 0.5076\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 408us/step - loss: 0.9682 - acc: 0.6364\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 473us/step - loss: 1.0497 - acc: 0.5909\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 389us/step - loss: 0.9310 - acc: 0.5985\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 445us/step - loss: 0.9027 - acc: 0.6667\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 372us/step - loss: 0.8047 - acc: 0.7348\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 386us/step - loss: 0.8390 - acc: 0.6818\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 408us/step - loss: 0.7844 - acc: 0.6970\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 450us/step - loss: 0.7721 - acc: 0.7273\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 520us/step - loss: 0.7743 - acc: 0.7197\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 377us/step - loss: 0.7059 - acc: 0.7273\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 471us/step - loss: 0.6414 - acc: 0.8030\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 480us/step - loss: 0.6994 - acc: 0.7424\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 392us/step - loss: 0.5179 - acc: 0.8106\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 531us/step - loss: 0.5578 - acc: 0.8182\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 601us/step - loss: 0.6185 - acc: 0.8030\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 503us/step - loss: 0.5307 - acc: 0.8409\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 519us/step - loss: 0.5226 - acc: 0.8182\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 384us/step - loss: 0.4708 - acc: 0.8561\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 334us/step - loss: 0.4538 - acc: 0.8561\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 374us/step - loss: 0.4079 - acc: 0.9015\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 402us/step - loss: 0.3536 - acc: 0.9167\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 598us/step - loss: 0.3684 - acc: 0.8788\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 635us/step - loss: 0.3367 - acc: 0.9015\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 476us/step - loss: 0.3047 - acc: 0.9394\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 451us/step - loss: 0.2649 - acc: 0.9394\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 613us/step - loss: 0.2874 - acc: 0.9470\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 485us/step - loss: 0.3007 - acc: 0.9091\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 619us/step - loss: 0.1988 - acc: 0.9697\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 551us/step - loss: 0.2117 - acc: 0.9621\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 783us/step - loss: 0.2500 - acc: 0.9318\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 628us/step - loss: 0.2034 - acc: 0.9848\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 692us/step - loss: 0.2036 - acc: 0.9545\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 556us/step - loss: 0.1789 - acc: 0.9697\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 701us/step - loss: 0.2029 - acc: 0.9470\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 516us/step - loss: 0.1891 - acc: 0.9697\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 474us/step - loss: 0.1526 - acc: 0.9773\n"
     ]
    }
   ],
   "source": [
    "# Training of the model and Setting hyperparameters for the model\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 50, batch_size=32,shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of the trained model \n",
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071428571428571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the accuracy of the algorithm\n",
    "float(sum(pred==Y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['he', 'got', 'a', 'raise'] üç¥ üòÑ\n",
      "5\n",
      "['he', 'is', 'a', 'good', 'friend'] üòÑ ‚ù§\n",
      "6\n",
      "['I', 'am', 'upset'] üòÑ ‚ù§\n",
      "7\n",
      "['We', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight'] üç¥ ‚ù§\n",
      "11\n",
      "['work', 'is', 'hard'] üòÑ üòû\n",
      "12\n",
      "['This', 'girl', 'is', 'messing', 'with', 'me'] üòÑ üòû\n",
      "13\n",
      "['are', 'you', 'serious', 'ha', 'ha'] üòû üòÑ\n",
      "16\n",
      "['work', 'is', 'horrible'] üòÑ üòû\n",
      "17\n",
      "['Congratulation', 'for', 'having', 'a', 'baby'] üç¥ üòÑ\n",
      "18\n",
      "['stop', 'messing', 'around'] üòÑ üòû\n",
      "23\n",
      "['she', 'is', 'a', 'bully'] ‚ù§ üòû\n",
      "25\n",
      "['I', 'am', 'upset'] üòÑ üòû\n",
      "26\n",
      "['I', 'worked', 'during', 'my', 'birthday'] ‚ù§ üòû\n",
      "27\n",
      "['My', 'grandmother', 'is', 'the', 'love', 'of', 'my', 'life'] üòû ‚ù§\n",
      "29\n",
      "['valentine', 'day', 'is', 'near'] üç¥ ‚ù§\n",
      "30\n",
      "['I', 'miss', 'you', 'so', 'much'] üòû ‚ù§\n",
      "39\n",
      "['I', 'like', 'to', 'laugh'] ‚ù§ üòÑ\n",
      "41\n",
      "['I', 'like', 'your', 'jacket'] ‚ù§ üòÑ\n",
      "46\n",
      "['What', 'you', 'did', 'was', 'awesome'] üòû üòÑ\n",
      "50\n",
      "['yesterday', 'we', 'lost', 'again'] ‚öæ üòû\n",
      "51\n",
      "['family', 'is', 'all', 'I', 'have'] üòû ‚ù§\n",
      "55\n",
      "['I', 'did', 'not', 'have', 'breakfast'] üç¥ üòû\n"
     ]
    }
   ],
   "source": [
    "# Printing the sentences with the predicted and labled emoji\n",
    "for ix in range(embedding_matrix_test.shape[0]):\n",
    "    \n",
    "    if pred[ix] != Y_test[ix]:\n",
    "        print(ix)\n",
    "        print (test[0][ix],end=\" \")\n",
    "        print (emoji.emojize(emoji_dict[pred[ix]], use_aliases=True),end=\" \")\n",
    "        print (emoji.emojize(emoji_dict[Y_test[ix]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for our random sentence\n",
    "x = ['i', 'do', 'think','this', 'class', 'is', 'very', 'interesting']\n",
    "\n",
    "x_ = np.zeros((1,10,50))\n",
    "\n",
    "for ix in range(len(x)):\n",
    "    x_[0][ix] = embeddings_index[x[ix].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  - Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 223,877\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Loss ,Optimiser for model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5926 - acc: 0.2348\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5371 - acc: 0.3485\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4919 - acc: 0.3409\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4429 - acc: 0.3939\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3951 - acc: 0.3939\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3285 - acc: 0.4621\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.1927 - acc: 0.5606\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.0565 - acc: 0.6288\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9396 - acc: 0.6515\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8589 - acc: 0.6667\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.7421 - acc: 0.7424\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6272 - acc: 0.7652\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5663 - acc: 0.8030\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5494 - acc: 0.8106\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5283 - acc: 0.7879\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6066 - acc: 0.7803\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5189 - acc: 0.8106\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4016 - acc: 0.8333\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4015 - acc: 0.8561\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3532 - acc: 0.8864\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3106 - acc: 0.8939\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2701 - acc: 0.9015\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2725 - acc: 0.9015\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2960 - acc: 0.8636\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1916 - acc: 0.9242\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3357 - acc: 0.8712\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3895 - acc: 0.8561\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3095 - acc: 0.8939\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2585 - acc: 0.9318\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2302 - acc: 0.9394\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3673 - acc: 0.8939\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2214 - acc: 0.9318\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2154 - acc: 0.9394\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1917 - acc: 0.9470\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1988 - acc: 0.9318\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1745 - acc: 0.9470\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5321 - acc: 0.8258\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4877 - acc: 0.8258\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3154 - acc: 0.8788\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2883 - acc: 0.9015\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2429 - acc: 0.9394\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2047 - acc: 0.9621\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1305 - acc: 0.9773\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1276 - acc: 0.9697\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1108 - acc: 0.9773\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0985 - acc: 0.9621\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0844 - acc: 0.9773\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0767 - acc: 0.9773\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0322 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 50, batch_size=32,shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of trained model\n",
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6964285714285714"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating accuracy / score  of the model\n",
    "float(sum(pred==Y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['he', 'got', 'a', 'raise'] üòû üòÑ\n",
      "5\n",
      "['he', 'is', 'a', 'good', 'friend'] üòÑ ‚ù§\n",
      "6\n",
      "['I', 'am', 'upset'] üòû ‚ù§\n",
      "7\n",
      "['We', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight'] üòÑ ‚ù§\n",
      "12\n",
      "['This', 'girl', 'is', 'messing', 'with', 'me'] ‚ù§ üòû\n",
      "13\n",
      "['are', 'you', 'serious', 'ha', 'ha'] üòû üòÑ\n",
      "21\n",
      "['you', 'brighten', 'my', 'day'] ‚ù§ üòÑ\n",
      "26\n",
      "['I', 'worked', 'during', 'my', 'birthday'] üòÑ üòû\n",
      "28\n",
      "['enjoy', 'your', 'break'] ‚öæ üòÑ\n",
      "29\n",
      "['valentine', 'day', 'is', 'near'] üòÑ ‚ù§\n",
      "32\n",
      "['My', 'life', 'is', 'so', 'boring'] ‚ù§ üòû\n",
      "37\n",
      "['I', 'am', 'starving'] üòû üç¥\n",
      "41\n",
      "['I', 'like', 'your', 'jacket'] ‚ù§ üòÑ\n",
      "48\n",
      "['I', 'want', 'to', 'joke'] üòû üòÑ\n",
      "49\n",
      "['go', 'away'] ‚öæ üòû\n",
      "50\n",
      "['yesterday', 'we', 'lost', 'again'] ‚öæ üòû\n",
      "55\n",
      "['I', 'did', 'not', 'have', 'breakfast'] üç¥ üòû\n"
     ]
    }
   ],
   "source": [
    "# Printing the sentences with the predicted and the labelled emoji\n",
    "for ix in range(embedding_matrix_test.shape[0]):\n",
    "    \n",
    "    if pred[ix] != Y_test[ix]:\n",
    "        print(ix)\n",
    "        print (test[0][ix],end=\" \")\n",
    "        print (emoji.emojize(emoji_dict[pred[ix]], use_aliases=True),end=\" \")\n",
    "        print (emoji.emojize(emoji_dict[Y_test[ix]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
